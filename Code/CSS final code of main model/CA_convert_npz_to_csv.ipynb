{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.optimize import least_squares\n",
    "import powerlaw\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.ndimage import convolve"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook is to convert the npz.file to a csv.file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Constants\n",
    "grid_size = 50\n",
    "states = {'V': 0, 'H': 1, 'I': 2, 'C': 3}  # V: vacant, H: housing, I: industrial, C: commercial\n",
    "growth_rates = {1: 0.003, 2: 0.001, 3: 0.0014}  \n",
    "num_iterations = 30  # Number of iterations\n",
    "\n",
    "# Initialize the grid and counts\n",
    "\n",
    "counts = {0: grid_size * grid_size, 1: 0, 2: 0, 3: 0}\n",
    "\n",
    "def initial_land_use(seed_number, grid_size, plot=True):\n",
    "    np.random.seed(seed_number)\n",
    "    \n",
    "    grid = np.zeros((grid_size, grid_size), dtype=int)\n",
    "\n",
    "    # Define initial conditions\n",
    "    center_x, center_y = grid_size // 2, grid_size // 2\n",
    "    \n",
    "    # Randomly select positions for commercial cells\n",
    "    commercial_cells = []\n",
    "    num_commercial = 3\n",
    "    min_dist_commercial = 1  # Minimum distance from center\n",
    "    \n",
    "    while len(commercial_cells) < num_commercial:\n",
    "        x = np.random.randint(center_x - min_dist_commercial, center_x + min_dist_commercial + 1)\n",
    "        y = np.random.randint(center_y - min_dist_commercial, center_y + min_dist_commercial + 1)\n",
    "        if (x, y) not in commercial_cells:\n",
    "            commercial_cells.append((x, y))\n",
    "\n",
    "    residential_cells = []\n",
    "    num_residential = 25\n",
    "    min_dist = 3  # Minimum distance from commercial cells\n",
    "\n",
    "    industrial_cells = []\n",
    "    num_industrial = 4\n",
    "    min_dist_industrial = 3  # Minimum distance from commercial cells\n",
    "\n",
    "    # Generate random residential cells around the commercial area\n",
    "    while len(residential_cells) < num_residential:\n",
    "        x = np.random.randint(center_x - min_dist, center_x + min_dist + 1)\n",
    "        y = np.random.randint(center_y - min_dist, center_y + min_dist + 1)\n",
    "        if (x, y) not in commercial_cells:\n",
    "            residential_cells.append((x, y))\n",
    "\n",
    "    # Generate random industrial cells around the commercial area\n",
    "    while len(industrial_cells) < num_industrial:\n",
    "        x = np.random.randint(center_x - min_dist_industrial, center_x + min_dist_industrial + 1)\n",
    "        y = np.random.randint(center_y - min_dist_industrial, center_y + min_dist_industrial + 1)\n",
    "        if (x, y) not in commercial_cells:\n",
    "            industrial_cells.append((x, y))\n",
    "\n",
    "    # Assign initial land use types\n",
    "    for x, y in commercial_cells:\n",
    "        grid[x, y] = states['C']  # Commercial\n",
    "    for x, y in residential_cells:\n",
    "        grid[x, y] = states['H']  # Residential\n",
    "    for x, y in industrial_cells:\n",
    "        grid[x, y] = states['I']  # Industrial\n",
    "\n",
    "    if plot:\n",
    "        # Set the figure size\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        cmap = plt.cm.colors.ListedColormap(['white', 'skyblue', 'grey', 'orange'])\n",
    "        plt.imshow(grid, cmap=cmap, origin='lower', vmin=0, vmax=3)\n",
    "        \n",
    "        # in the colorbar, change the label of 0 to 'Vacant', 1 to 'Housing', 2 to 'Industrial', 3 to 'Commercial'\n",
    "        cbar = plt.colorbar(ticks=[0, 1, 2, 3])\n",
    "        cbar.ax.set_yticklabels(['Vacant', 'Housing', 'Industrial', 'Commercial'])\n",
    "        # disable the x and y ticks\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        \n",
    "        \n",
    "        plt.title('Initial Land Use')\n",
    "        plt.show()\n",
    "\n",
    "    return grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_table = {\n",
    "    'Vacant_Commerce': {\n",
    "        'C': [6, 3.5, 3, 2.5, 2, 2, 2, 1.5, 1.5, 1.5, 1.5, 1, 1, 1, 1, 1, 1, 1],\n",
    "        'I': [0]*18,\n",
    "        'H': [4, 3.5, 3, 2.5, 2, 2, 2, 1.5, 1.5, 1.5, 1.5, 1, 1, 1, 1, 1, 1, 1],\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Vacant_Industry': {\n",
    "        'C': [0]*18,\n",
    "        'I': [3, 3, 2, 1, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "        'H': [-1, -1, 0] + [0]*15,\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Vacant_Housing': {\n",
    "        'C': [-2, -1, 2, 1, 1, 1, 0.5, 0.5, 0.4, 0.3, 0.2, 0.1, 0.1, 0.1, 0, 0, 0, 0],\n",
    "        'I': [-10, -10, -5, -3, -1] + [0]*13,\n",
    "        'H': [2, 2, 1.5, 1.5, 1, 1, 1, 1, 0.5, 0.5, 0.5, 0.5, 0.5, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Industry_Commerce': {\n",
    "        'C': [25, 15, 10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2],\n",
    "        'I': [-2, -2, -2] + [0]*15,\n",
    "        'H': [4, 3.5, 3, 2.5, 2, 2, 2, 1.5, 1.5, 1.5, 1.5, 1, 1, 1, 1, 1, 1, 1],\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Industry_Industry': {\n",
    "        'C': [0]*18,\n",
    "        'I': [0]*18,\n",
    "        'H': [0]*18,\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Industry_Housing': {\n",
    "        'C': [0]*18,\n",
    "        'I': [0]*18,\n",
    "        'H': [0]*18,\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Housing_Commerce': {\n",
    "        'C': [25, 15, 10, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2],\n",
    "        'I': [-10, -10, -5, -3, -1] + [0]*13,\n",
    "        'H': [4, 3.5, 3, 2.5, 2, 2, 2, 1.5, 1.5, 1.5, 1.5, 1, 1, 1, 1, 1, 1, 1],\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Housing_Industry': {\n",
    "        'C': [0]*18,\n",
    "        'I': [3, 3, 2, 1, 0, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2],\n",
    "        'H': [-1, -1, 0] + [0]*15,\n",
    "        'V': [0]*18\n",
    "    },\n",
    "    'Housing_Housing': {\n",
    "        'C': [0]*18,\n",
    "        'I': [0]*18,\n",
    "        'H': [0]*18,\n",
    "        'V': [0]*18\n",
    "    },\n",
    "}\n",
    "\n",
    "# Test of accessing a weight:\n",
    "transition = 'Vacant_Commerce'\n",
    "cell_type = 'H'\n",
    "distance_zone = 1\n",
    "# This is distance zone is from 0 to 17\n",
    "weight = weights_table[transition][cell_type][distance_zone]\n",
    "print(f\"The weight for transition={transition}, cell_type={cell_type}, distance_zone={distance_zone} is {weight}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_distance_zone(distance):\n",
    "    zone_mapping = {0: 1, 1: 1.4, 2: 2, 3: 2.2, 4: 2.8, 5: 3, 6: 3.2, 7: 3.6, 8: 4, 9: 4.1, 10: 4.2, 11: 4.5, 12: 5, 13: 5.1, 14: 5.4, 15: 5.7, 16: 5.8, 17: 6}\n",
    "    for zone, max_distance in reversed(list(zone_mapping.items())):\n",
    "        if distance >= max_distance:\n",
    "            return zone\n",
    "    return 0  # Return 0 if distance is less than the minimum specified distance\n",
    "\n",
    "def get_neighbourhood(grid, row, col, radius):\n",
    "    rows, cols = grid.shape\n",
    "    square_row_range = range(max(0, row - radius), min(rows, row + radius + 1))\n",
    "    square_col_range = range(max(0, col - radius), min(cols, col + radius + 1))\n",
    "    square_neighbourhood = grid[np.ix_(square_row_range, square_col_range)]\n",
    "    circle_mask = np.zeros_like(square_neighbourhood, dtype=bool)\n",
    "    distance_zones = np.zeros_like(square_neighbourhood, dtype=int)\n",
    "    # Adjusted center coordinates inside the neighbourhood\n",
    "    center = min(row, radius), min(col, radius)\n",
    "    for i in range(square_neighbourhood.shape[0]):\n",
    "        for j in range(square_neighbourhood.shape[1]):\n",
    "            distance = np.sqrt((center[0] - i) ** 2 + (center[1] - j) ** 2)\n",
    "            if distance <= radius:\n",
    "                circle_mask[i, j] = True\n",
    "                distance_zones[i, j] = get_distance_zone(distance)\n",
    "    circle_mask[center] = False  # Exclude the center cell\n",
    "    return square_neighbourhood[circle_mask], distance_zones[circle_mask]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cell_type_to_states(state):\n",
    "    if state == 'Vacant':\n",
    "        return 0\n",
    "    elif state == 'Housing':\n",
    "        return 1\n",
    "    elif state == 'Industry':\n",
    "        return 2\n",
    "    elif state == 'Commerce':\n",
    "        return 3\n",
    "\n",
    "def states_to_cell_type(state):\n",
    "    if state == 0:\n",
    "        return 'V'\n",
    "    elif state == 1:\n",
    "        return 'H'\n",
    "    elif state == 2:\n",
    "        return 'I'\n",
    "    elif state == 3:\n",
    "        return 'C'\n",
    "\n",
    "\n",
    "def calculate_transition_potentials(grid, alpha, weights_table, radius):\n",
    "    transition_potentials = np.zeros((grid.shape[0], grid.shape[1], 4))  # 4 possible states\n",
    "    transitions = ['Vacant_Commerce', 'Vacant_Industry', 'Vacant_Housing', 'Industry_Commerce', 'Industry_Industry',\n",
    "                   'Industry_Housing', 'Housing_Commerce', 'Housing_Industry', 'Housing_Housing']\n",
    "    \n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(grid.shape[1]):\n",
    "            neighbourhood, distance_zones = get_neighbourhood(grid, i, j, radius)\n",
    "            for transition in transitions:\n",
    "                # Extract the current state and desired state from the transition string\n",
    "                current_state, desired_state = transition.split('_')\n",
    "                \n",
    "                current_state_num = cell_type_to_states(current_state)\n",
    "                desired_state_num = cell_type_to_states(desired_state)\n",
    "                \n",
    "            \n",
    "                if grid[i, j] == current_state_num:\n",
    "                    sum_weights = 0\n",
    "                    for neighbor_state, distance_zone in zip(neighbourhood, distance_zones):\n",
    "                        \n",
    "                        neighbor_type = states_to_cell_type(neighbor_state)\n",
    "                        \n",
    "                        m_kd = weights_table[transition][neighbor_type][distance_zone]\n",
    "\n",
    "                        if neighbor_state == desired_state_num:\n",
    "                            sum_weights += m_kd\n",
    "\n",
    "                    \n",
    "                    R = np.random.uniform(0, 1)\n",
    "                    S = 1 + (-math.log(R))**alpha\n",
    "                    transition_potentials[i, j, desired_state_num] = S * (1 + sum_weights)\n",
    "    return transition_potentials\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(grid, weights_table, alpha, growth_rates, radius, seed, num_iterations, plot = False):\n",
    "    np.random.seed(seed)\n",
    "    grid_size = grid.shape[0]\n",
    "\n",
    "    counts = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            counts[grid[i, j]] += 1\n",
    "\n",
    "    print(f\"Initial counts: {counts}\")\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        transition_potentials = calculate_transition_potentials(grid, alpha, weights_table, radius)\n",
    "\n",
    "        highest_potentials = {}\n",
    "        for i in range(grid_size):\n",
    "            for j in range(grid_size):\n",
    "                if grid[i, j] == states['V']:\n",
    "                    potential_states = ['H', 'I', 'C']\n",
    "                elif grid[i, j] == states['H']:\n",
    "                    potential_states = ['I', 'C']\n",
    "                elif grid[i, j] == states['I']:\n",
    "                    potential_states = ['C']\n",
    "                else:\n",
    "                    potential_states = []\n",
    "                    \n",
    "                if potential_states:\n",
    "                    highest_potentials[(i, j)] = max(potential_states, key=lambda state: transition_potentials[i, j, states[state]])\n",
    "\n",
    "        for new_state_key in sorted(states, key=lambda k: states[k], reverse=True):\n",
    "            new_state = states[new_state_key]\n",
    "            if new_state_key != 'V':\n",
    "                num_to_convert = int(grid_size * grid_size * growth_rates[new_state_key])\n",
    "                potential_cells = [(i, j) for i, j in highest_potentials.keys() if highest_potentials[(i, j)] == new_state_key]\n",
    "                potential_cells.sort(key=lambda cell: transition_potentials[cell[0], cell[1], states[highest_potentials[cell]]], reverse=True)\n",
    "                \n",
    "                for cell in potential_cells[:num_to_convert]:\n",
    "                    counts[grid[cell]] -= 1\n",
    "                    counts[new_state] += 1\n",
    "                    grid[cell] = new_state\n",
    "\n",
    "        # print the percentage of work done\n",
    "        print(f\"Percentage of work done: {(iteration+1)/num_iterations*100:.2f}%\", end='\\r')\n",
    "    print(f\"Final counts: {counts}\")    \n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        cmap = plt.cm.colors.ListedColormap(['white', 'skyblue', 'grey', 'orange'])\n",
    "        plt.imshow(grid, cmap=cmap, origin='lower', vmin=0, vmax=3)\n",
    "        plt.colorbar(ticks=[0, 1, 2, 3], label='Land Use')\n",
    "        plt.title('Final Land Use')\n",
    "        plt.show()\n",
    "\n",
    "    return grid  \n",
    "\n",
    "\n",
    "\n",
    "growth_rates = {\n",
    "    'H': 0.01,  \n",
    "    'I': 0.002,\n",
    "    'C': 0.001,\n",
    "}\n",
    "\n",
    "\n",
    "num_iterations = 50\n",
    "# Run the simulation\n",
    "grid = initial_land_use(seed_number=0, grid_size=75, plot=False)\n",
    "final_grid = run_simulation(grid, weights_table, alpha=2.5, growth_rates=growth_rates, radius = 6, seed=45, num_iterations=num_iterations, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxcount(Z, k):\n",
    "    S = np.add.reduceat(\n",
    "        np.add.reduceat(Z, np.arange(0, Z.shape[0], k), axis=0),\n",
    "        np.arange(0, Z.shape[1], k), axis=1)\n",
    "    return len(np.where((S > 0) & (S < k*k))[0])\n",
    "\n",
    "def fractal_dimension2(Z, threshold=0.9):\n",
    "    assert(len(Z.shape) == 2)\n",
    "\n",
    "    Z = (Z > threshold)\n",
    "    p = min(Z.shape)\n",
    "    n = 2**np.floor(np.log(p)/np.log(2))\n",
    "    n = int(np.log(n)/np.log(2))\n",
    "\n",
    "    # Build successive box sizes (from 2**n down to 2**1)\n",
    "    sizes = 2**np.arange(n, 1, -1)\n",
    "\n",
    "    # Actual box counting with decreasing size\n",
    "    counts = []\n",
    "    for size in sizes:\n",
    "        counts.append(boxcount(Z, size))\n",
    "\n",
    "    # Fit the successive log(sizes) with log(counts)\n",
    "    coeffs = np.polyfit(np.log(sizes), np.log(counts), 1)\n",
    "    return -coeffs[0]\n",
    "\n",
    "def autocorrelation_2d(grid):\n",
    "    # Flatten the 2D grid to a 1D array\n",
    "    grid_flattened = grid.flatten()\n",
    "\n",
    "    # Compute the autocorrelation of the 1D array\n",
    "    autocorr = np.correlate(grid_flattened, grid_flattened, mode='full')\n",
    "\n",
    "    # Normalize the autocorrelation\n",
    "    autocorr = autocorr / np.max(autocorr)\n",
    "\n",
    "    # Return the autocorrelation\n",
    "    return np.mean(autocorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_joint_counts(grid):\n",
    "    # Initialize a dictionary to store the joint counts\n",
    "    joint_counts = {}\n",
    "\n",
    "    # Loop over each cell in the grid\n",
    "    for i in range(1, grid.shape[0] - 1):\n",
    "        for j in range(1, grid.shape[1] - 1):\n",
    "            # Get the state of the cell and its neighbors\n",
    "            state_vector = tuple(grid[i-1:i+2, j-1:j+2].flatten())\n",
    "\n",
    "            # Increment the count for this state vector\n",
    "            if state_vector in joint_counts:\n",
    "                joint_counts[state_vector] += 1\n",
    "            else:\n",
    "                joint_counts[state_vector] = 1\n",
    "\n",
    "    return joint_counts\n",
    "\n",
    "def calculate_conditional_entropy_Moore(grid):\n",
    "    # Calculate the joint counts\n",
    "    joint_counts = calculate_joint_counts(grid)\n",
    "\n",
    "    # Calculate the joint probabilities\n",
    "    total_counts = sum(joint_counts.values())\n",
    "    joint_probabilities = {state_vector: count / total_counts for state_vector, count in joint_counts.items()}\n",
    "\n",
    "    # Calculate the marginal probabilities\n",
    "    marginal_probabilities = {}\n",
    "    for state_vector, joint_probability in joint_probabilities.items():\n",
    "        cell_state = state_vector[4]  # The cell's state is at the center of the state vector\n",
    "        if cell_state in marginal_probabilities:\n",
    "            marginal_probabilities[cell_state] += joint_probability\n",
    "        else:\n",
    "            marginal_probabilities[cell_state] = joint_probability\n",
    "\n",
    "    # Calculate the conditional probabilities and the conditional entropy\n",
    "    conditional_entropy = 0\n",
    "    for state_vector, joint_probability in joint_probabilities.items():\n",
    "        cell_state = state_vector[4]\n",
    "        conditional_probability = joint_probability / marginal_probabilities[cell_state]\n",
    "        conditional_entropy -= conditional_probability * np.log2(conditional_probability)\n",
    "\n",
    "    return conditional_entropy\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering(m, rtype):\n",
    "    \"\"\" Algorithm for finding clusters and labeling them. \n",
    "    INPUT: Matrix m with occupied 1 and unoccupied 0\"\"\"\n",
    "    assert type(rtype) == int\n",
    "    assert m.shape[0] == m.shape[1]\n",
    "    \n",
    "    dim = m.shape[0]\n",
    "    largest_label = 0\n",
    "    label = np.zeros([dim, dim])\n",
    "    for x in range(dim):\n",
    "        for y in range(dim):\n",
    "            above = m[x-1, y]\n",
    "            left = m[x, y-1]\n",
    "            # For the boundary conditions, set above and left to zero.\n",
    "            if x == 0:\n",
    "                above = 0\n",
    "            if y == 0:\n",
    "                left = 0\n",
    "            # Assign cluster IDs according to neighbours   \n",
    "            if m[x,y] == rtype:\n",
    "                if above != rtype and left != rtype: # no neighbors, new cluster id\n",
    "                    largest_label += 1\n",
    "                    label[x,y] = largest_label\n",
    "                elif above == rtype and left != rtype: # cluster extends from above, change id\n",
    "                    label[x,y] = label[x-1,y]\n",
    "                elif above != rtype and left == rtype: # cluster extends from left, change id\n",
    "                    label[x,y] = label[x,y-1]\n",
    "                elif above == rtype and left == rtype: # both belong to cluster, make a union\n",
    "                    m, label = cluster_union(m, label, x, y)             \n",
    "    return label\n",
    "            \n",
    "def cluster_union(m, label, x, y):\n",
    "    \"\"\"\n",
    "    Union the two clusters and labels both clusters the same.\n",
    "    \"\"\"\n",
    "    if label[x-1,y] == label[x,y-1]: # If labels are the same, then set x,y as same label\n",
    "        label[x,y] = label[x-1,y]\n",
    "        return m, label\n",
    "    else: # else different clusters so rename one\n",
    "        new_id, old_id = np.min([label[x-1,y], label[x,y-1]]), np.max([label[x-1,y], label[x,y-1]])\n",
    "        label[x,y] = new_id # set label of current x,y\n",
    "        label[label == old_id] = new_id # change all old IDs to the new one\n",
    "    return m, label\n",
    "\n",
    "def run_clustering(m):\n",
    "    \"\"\"\n",
    "    Runs the clustering algorithm for each of the cell types, returns a pandas dataframe with the columns cluster size, count, id.\n",
    "    INPUT: the matrix with the different IDs in the cells. \n",
    "    \"\"\"\n",
    "    clusters = pd.DataFrame()\n",
    "    # Run each of the cluster types in a loop\n",
    "    for i in np.unique(m)[1:]: # not the zeros\n",
    "        cluster_ids = clustering(m, int(i))\n",
    "        cluster_size = np.unique(cluster_ids, return_counts=True) # count size of clusters in matrix of cell types\n",
    "        size, count = np.unique(cluster_size[1][1:], return_counts=True) # select only the cells that contain something (first element is empty)\n",
    "        # f\n",
    "        clusters = pd.concat([clusters, pd.DataFrame([size, count, i * np.ones(len(count))]).T], axis = 0)\n",
    "\n",
    "    clusters.columns = ['Cluster_size','Cluster_count','cell_type']\n",
    "    return clusters\n",
    "\n",
    "\n",
    "def power_law(x, a, b):\n",
    "    return a*np.power(x, b)\n",
    "\n",
    "def fractal_dimension(m):\n",
    "    \"\"\"\n",
    "    Calculates the fractal dimension of the occupancy for each radius\n",
    "    \"\"\"\n",
    "    center = m.shape[0] // 2\n",
    "    dim = m.shape[0] # get the array dimension\n",
    "    distance = np.zeros([dim,dim])\n",
    "    m = np.where(m > 0, 1, 0)\n",
    "    \n",
    "    radius = np.array(range(1, center)) # sets the range to loop over for occupancy\n",
    "    occupied_cells = np.zeros(center - 1)\n",
    "    for i in range(dim):\n",
    "        for j in range(dim):\n",
    "            distance[i,j] = np.sqrt((center - i) ** 2 + (center - j) ** 2)\n",
    "    # logic is to filter spots within distance, then multiply with m matrix to find spots where there are occupants\n",
    "    # assuming empty spots are marked with zero and sum the spots within raidus and with occupants.\n",
    "\n",
    "    for r in range(len(radius)): # loop through radiuses and chekc which ones are within area and then count cells occupied.\n",
    "        current_distance = np.where(distance < radius[r], 1, 0)\n",
    "        \n",
    "        area = (current_distance * m).sum()\n",
    "        occupied_cells[r] = area\n",
    "        \n",
    "    pars, cov = curve_fit(f=power_law, xdata=radius, ydata=occupied_cells, p0=[0, 0]) # gives higher weight to large values\n",
    "    fractal_d = np.polyfit(np.log(radius), np.log(occupied_cells), 1) # gives higher weight to small values\n",
    "    return fractal_d, occupied_cells, radius, pars\n",
    "\n",
    "\n",
    "def conditional_entropy(grid):\n",
    "    counter = Counter()\n",
    "    total_count = 0\n",
    "\n",
    "    for i in range(grid.shape[0]):\n",
    "        for j in range(grid.shape[1]):\n",
    "            state = grid[i, j]\n",
    "            counter[state] += 1\n",
    "            total_count += 1\n",
    "\n",
    "    conditional_entropy = 0\n",
    "    for state, count in counter.items():\n",
    "        probability = count / total_count\n",
    "        conditional_entropy -= probability * np.log2(probability)\n",
    "\n",
    "    return conditional_entropy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------- Start Conversion --------------------- "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha vs Grid Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Cluster_size  Cluster_count  cell_type  alpha  grid_size  growth_rate_C  \\\n",
      "0           1.0            5.0        1.0    1.0         30          0.001   \n",
      "1         412.0            1.0        1.0    1.0         30          0.001   \n",
      "0          54.0            1.0        2.0    1.0         30          0.001   \n",
      "0           3.0            1.0        3.0    1.0         30          0.001   \n",
      "0           1.0            7.0        1.0    1.0         40          0.001   \n",
      "\n",
      "   fractal_dim  condi_entropy  autocorr  \n",
      "0     1.229716      11.588459  0.240164  \n",
      "1     1.229716      11.588459  0.240164  \n",
      "0     1.229716      11.588459  0.240164  \n",
      "0     1.229716      11.588459  0.240164  \n",
      "0     0.893139      12.346983  0.214241  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load npz file\n",
    "data = np.load('final_grids3.npz')\n",
    "\n",
    "alphas = [1, 1.25, 1.5, 1.75, 2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4, 4.25, 4.5, 4.75, 5]\n",
    "grid_sizes = [30, 40, 50, 60, 70, 80, 90, 100, 200, 400]\n",
    "growth_rate_C = 0.001  # Fixed growth rate\n",
    "\n",
    "# Initialize a list to store clustering dataframes for each combination of alpha and grid size\n",
    "cluster_info_list = []\n",
    "\n",
    "# Calculate fractal dimensions, conditional entropy, autocorrelation and cluster information for all combinations of alpha and grid size\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, grid_size in enumerate(grid_sizes):\n",
    "        key = f\"alpha_{alpha}_grid_{grid_size}_growth_rate_C_{growth_rate_C}\"\n",
    "        grid = data[key]\n",
    "\n",
    "        # Calculate fractal dimension\n",
    "        fractal_dim = fractal_dimension2(grid)\n",
    "\n",
    "        # Calculate conditional entropy\n",
    "        condi_entropy = calculate_conditional_entropy_Moore(grid)\n",
    "\n",
    "        # Calculate autocorrelation\n",
    "        autocorr = autocorrelation_2d(grid)\n",
    "\n",
    "        # Compute cluster information and add it to the list\n",
    "        clusters = run_clustering(grid)\n",
    "        clusters['alpha'] = alpha\n",
    "        clusters['grid_size'] = grid_size\n",
    "        clusters['growth_rate_C'] = growth_rate_C\n",
    "        clusters['fractal_dim'] = fractal_dim\n",
    "        clusters['condi_entropy'] = condi_entropy\n",
    "        clusters['autocorr'] = autocorr\n",
    "        cluster_info_list.append(clusters)\n",
    "\n",
    "data.close() \n",
    "\n",
    "# Combine all clustering dataframes into a single dataframe\n",
    "cluster_info_df = pd.concat(cluster_info_list)\n",
    "\n",
    "# View the first few rows of the dataframe\n",
    "print(cluster_info_df.head())\n",
    "\n",
    "# Store the data into a CSV file\n",
    "cluster_info_df.to_csv('cluster_info_size_and_Alpha.csv', index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Growth rate vs Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load npz file\n",
    "Grid_data1 = np.load('final_grids2.npz')\n",
    "\n",
    "alphas = [1.0, 1.125, 1.25, 1.375, 1.5, 1.625, 1.75, 1.875, 2.0, 2.125, 2.25, 2.375, 2.5, 2.625, 2.75, 2.875, 3.0, 3.125, 3.25, 3.375, 3.5, 3.625, 3.75, 3.875, 4.0]\n",
    "grid_size = 75  # Fixed grid size\n",
    "growth_rates_C = [0.0001, 0.0003, 0.0005, 0.0006, 0.0008, 0.001, 0.0012, 0.014, 0.016]\n",
    "\n",
    "# Initialize a list to store clustering dataframes for each combination of alpha and growth rate C\n",
    "cluster_info_list = []\n",
    "\n",
    "# Calculate fractal dimensions, conditional entropy, autocorrelation and cluster information for all combinations of alpha and growth rate C\n",
    "for i, alpha in enumerate(alphas):\n",
    "    for j, growth_rate_C in enumerate(growth_rates_C):\n",
    "        key = f\"alpha_{alpha}_grid_{grid_size}_growth_rate_C_{growth_rate_C}\"\n",
    "        grid = data[key]\n",
    "\n",
    "        # Calculate fractal dimension\n",
    "        fractal_dim = fractal_dimension2(grid)\n",
    "\n",
    "        # Calculate conditional entropy\n",
    "        condi_entropy = calculate_conditional_entropy_Moore(grid)\n",
    "\n",
    "        # Calculate autocorrelation\n",
    "        autocorr = autocorrelation_2d(grid)\n",
    "\n",
    "        # Compute cluster information and add it to the list\n",
    "        clusters = run_clustering(grid)\n",
    "        clusters['alpha'] = alpha\n",
    "        clusters['growth_rate_C'] = growth_rate_C\n",
    "        clusters['fractal_dim'] = fractal_dim\n",
    "        clusters['condi_entropy'] = condi_entropy\n",
    "        clusters['autocorr'] = autocorr\n",
    "        cluster_info_list.append(clusters)\n",
    "\n",
    "data.close()  # Close the data when you're done with it\n",
    "\n",
    "# Combine all clustering dataframes into a single dataframe\n",
    "cluster_info_df = pd.concat(cluster_info_list)\n",
    "\n",
    "# View the first few rows of the dataframe\n",
    "print(cluster_info_df.head())\n",
    "\n",
    "# Store the data into a CSV file\n",
    "cluster_info_df.to_csv('cluster_info.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
